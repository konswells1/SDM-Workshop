---
title: "Simple model fitting"
format: html
editor: visual
draft: false
---

```{r}
#| label: pagesetup-simpleSDM
#| echo: false
#| warning: false
#| message: false
#| include: false

# Load required packages
source("scripts/load_packages.R")

# Load shared environmental and species data
source("scripts/shared_sdm_data.R")

# Load shared SDM models
source("scripts/shared_sdm_models.R")
```

<br>

We now arrive at the core of species distribution modelling (SDM): **fitting the model**. Having prepared occurrence, background, and environmental data, this section introduces a foundational yet flexible approach — the **generalised linear model (GLM)** to estimate habitat suitability for *Rhinolophus hipposideros* across the UK.

SDMs quantify relationships between observed species distributions and environmental predictors, then project these relationships in space or time to identify potentially suitable areas under current or future conditions. While numerous algorithms exist, including MaxEnt, Random Forest, Boosted Regression Trees, and ensemble methods — the choice of model should reflect the modelling objective: inference, spatial prediction, or forecasting (Zurell et al. 2020).

GLMs, despite being statistically "simpler" than many machine learning alternatives, remain widely used because they are interpretable, computationally efficient, and well-suited to presence–background data. However, building meaningful SDMs still requires rigorous conceptualisation:

Are the data spatially biased or autocorrelated?

Are predictor variables collinear or ecologically redundant?

Is the model too simple or overly complex?

Are we modelling for understanding, mapping, or future projection?

In this session, we will fit a logistic regression model using key bioclimatic and topographic predictors. You will explore how to interpret model coefficients, predict across environmental space, and visualise suitability maps. This exercise lays the foundation for more advanced techniques — including model validation, spatial transfer, and ensembling, which we will explore in subsequent sessions.

For further background, see foundational SDM texts such as [Elith & Leathwick (2009)](https://www.annualreviews.org/content/journals/10.1146/annurev.ecolsys.110308.120159), and [Franklin (2010)](https://doi.org/10.1111/j.1472-4642.2010.00641.x), and methodological overviews and tutorials (e.g., [Zurell et al. 2020](https://doi.org/10.1111/ecog.04960), [Araújo et al. 2019)](https://www.science.org/doi/10.1126/sciadv.aat4858)).

<br>

::: {.callout-note collapse="true" icon="info"}
### Model fitting is an iterative process

While SDMs are often presented as a sequence of discrete steps — from data preparation to modelling and projection — the process is inherently iterative.

Fitting a model is rarely the endpoint. Often, model results reveal issues that require revisiting earlier decisions, such as:

Re-examining environmental predictors (e.g., removing collinear or ecologically irrelevant variables)

Adjusting background sampling to better reflect sampling bias

Filtering or cleaning occurrence data more stringently

Refining the study extent or resolution to match ecological realism

Each modelling decision can influence not only model performance, but also ecological interpretation and predictive transferability. As such, iteration is not a failure — it's good modelling practice. Treat each round of model fitting as an opportunity to improve clarity, parsimony, and ecological relevance.

📌 Think of model fitting not as a straight line, but as a feedback loop between conceptualisation, data, and interpretation.
:::

<br>

## 1. Fit a basic binomial GLM (logistic regression)

<br>

```{r}
#| label: fig-glm-illustration
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Illustration of presence–absence data for bats collected across forest stands differing in structure and rainfall. This figure conceptually represents how species distribution modelling (SDM) explores patterns of habitat suitability by linking species occurrence to environmental conditions. Scientific questions, such as 'Which environmental factors influence bat presence?', should guide the selection of predictors and model structure. These questions can be formalised using a generalised linear model (GLM), where presence–absence data are modelled as a function of habitat characteristics like forest type, or rainfall."

#| 
#| 
#| fig-align: center
#| out-width: 60%
#| number: false

knitr::include_graphics("images/glm_illustration.jpg")
```

<br>

::: {.callout-note collapse="true" title="GLM refresher: Logistic regression basics"}
Before applying generalised linear models (GLMs) in species distribution modelling, let’s briefly revisit the fundamentals of logistic regression — the most common approach for modelling binary outcomes, such as species presence or absence.

Presence–absence data are common in ecological and environmental research, but also in many other domains, such as infection status in epidemiology or success/failure in behavioural studies. Logistic regression models the **probability** of an event (e.g., species presence) as a function of one or more predictors, using a logit link function to map probabilities to the real line.

To illustrate, we begin with a simple example — random presence–absence data simulated as Bernoulli trials:

```{r}
#| label: sim-bernoulli
#| echo: true
#| include: true
#| warning: false
#| message: false

# Draw random binary outcomes (e.g., 10% chance of presence)
y <- rbinom(50, 1, 0.1)

# Observed mean presence probability
mu_y <- mean(y)
mu_y
```

This observed mean can be estimated with a logistic regression model. A model with no predictors is an intercept-only model:

```{r}
#| label: glm-demo1
#| echo: true
#| include: true
#| warning: false
#| message: false

# Intercept-only GLM
mod <- glm(y ~ 1, family = "binomial")

# Inspect design matrix (only intercept)
model.matrix(mod)

# Model summary
summary(mod)
```

Because logistic regression uses the logit link, model coefficients are on the log-odds scale. To convert to probabilities, we apply the inverse-logit (or logistic) function:

```{r}
#| label: invlogit
#| echo: true
#| include: true
#| warning: false
#| message: false

# Define inverse logit function
invlogit <- function(x) { exp(x) / (1 + exp(x)) }

# Estimate mean probability from model
mu_mod <- invlogit(coef(mod))
mu_mod
```

This simple model demonstrates how GLMs estimate the expected occurrence probability of a binary outcome. Understanding this structure is essential for interpreting more complex SDMs where environmental covariates explain spatial patterns in species occurrence.

We now move on to fitting such models using actual species and environmental data.
:::

### 1.1 Fitting the first GLM: a single environmental predictor

We now fit our first statistical species distribution model: a **generalised linear model (GLM)** with a **logit link** function and a **binomial error distribution**.

Generalised linear models (GLMs) extend ordinary least squares regression by allowing response variables with non-normal distributions and by using link functions to relate the expected value of the response to a linear combination of predictors. In our case:

-   **Response variable**: species occurrence (`pa`, 1 = presence, 0 = pseudo-absence)\
-   **Predictor**: one environmental covariate (here, `elevation`)\
-   **Model family**: `binomial` with `logit` link (logistic regression, applicable to a binary response variable)

This simple model quantifies how occurrence probability of *Rhinolophus hipposideros* varies along an environmental gradient.

```{r}
#| label: glm-single-fit
#| echo: true
#| include: true
#| message: false
#| warning: false

# Make sure sdm_df_clean$pa contains 0/1 numeric values, not factors
sdm_df_clean$pa <- as.numeric(sdm_df_clean$pa == 1)

# Fit logistic regression with elevation as the only predictor
glm_elev <- glm(pa ~ elevation,
                data = sdm_df_clean,
                family = binomial(link = "logit"))

summary(glm_elev)
```

The coefficients from a logistic regression are expressed on the log-odds scale. The intercept can be transformed with the logistic (inverse-logit) function to give the baseline probability of occurrence (at predictor = 0). For slope terms, exponentiation (exp()) gives the odds ratio associated with a one-unit change in the predictor, rather than a direct probability

```{r}
#| label: glm-coef-prob
#| echo: true
#| include: true
#| message: false
#| warning: false

# Define inverse logit
invlogit <- function(x) exp(x) / (1 + exp(x))

# Convert intercept to probability
invlogit(coef(glm_elev)[1])

# Odds ratio for 1-unit change in elevation
exp(coef(glm_elev)["elevation"])
```

Visualising the fitted response curve

To make the model more intuitive, we can plot the observed data and overlay the fitted probability curve.

```{r}
#| label: fig-glm-elev
#| echo: true
#| include: true
#| message: false
#| warning: false
#| fig-cap: "Relationship between elevation and probability of occurrence for *R. hipposideros* under a logistic regression model."
#| fig-align: center
#| out-width: 70%

# Generate prediction grid
elev_seq <- data.frame(elevation = seq(min(sdm_df_clean$elevation, na.rm = TRUE),
                                       max(sdm_df_clean$elevation, na.rm = TRUE),
                                       length.out = 200))

# Predict occurrence probability
elev_seq$pred_prob <- predict(glm_elev, newdata = elev_seq, type = "response")

# Plot data + fitted curve
ggplot(sdm_df_clean, aes(x = elevation, y = pa)) +
  geom_jitter(height = 0.05, alpha = 0.3, colour = "darkblue") +
  geom_line(data = elev_seq, aes(x = elevation, y = pred_prob),
            colour = "firebrick", linewidth = 1.2) +
  labs(x = "Elevation (m)",
       y = "Habitat suitability (scaled 0–1)",
       title = "GLM with elevation as predictor") +
  theme_minimal(base_size = 14)
```

::: {.callout-note collapse="true" title="Interpreting the elevation-only GLM"}
A positive slope means that the relative probability of occurrence increases with elevation.

A negative slope means that the relative probability of occurrence decreases with elevation.

The intercept reflects the baseline log-odds, here at elevation = 0. Note that interpreting the intercept assumes a meaningful value at 'elevation = 0', which may be outside the observed range. It is often better to center predictors (e.g., subtract mean elevation or use the 'scale()' function for scaling all variables) for interpretability.

While simple, this first GLM illustrates the core mechanics of SDMs: linking species occurrence data to environmental gradients. However, **because we use presence–pseudoabsence data, the fitted values should not be interpreted as absolute occurrence probabilities** — the number of background points (the “zeros”) is arbitrary. Instead, model outputs represent relative suitability across the environmental gradient.

In practice, species–environment relationships are often non-linear, motivating the use of transformations (e.g. quadratic terms) or more flexible algorithms.
:::

<br>

### 1.2 Extending the GLM: quadratic response curve

Species–environment relationships are often non-linear: too cold or too hot, too wet or too dry. A quadratic term allows us to capture such unimodal responses.

We use the poly() function in R, which orthogonalises polynomial terms to reduce collinearity.

```{r}
#| label: glm-elev-quad
#| echo: true
#| message: false
#| warning: false

# Fit logistic regression with 2nd order polynomial for elevation
glm_elev_poly <- glm(pa ~ poly(elevation, 2),
                     data = sdm_df_clean,
                     family = binomial(link = "logit"))

summary(glm_elev_poly)
```

**Visualising the quadratic response**

```{r}
#| label: fig-glm-elev-poly
#| fig-cap: "Quadratic logistic regression showing unimodal response of *R. hipposideros* to elevation."
#| fig-align: center
#| out-width: 70%

# Predict occurrence probability for elevation range
elev_seq$pred_prob_poly <- predict(glm_elev_poly,
                                   newdata = elev_seq,
                                   type = "response")

# Plot linear vs quadratic fits
ggplot(sdm_df_clean, aes(x = elevation, y = pa)) +
  geom_jitter(height = 0.05, alpha = 0.3, colour = "darkblue") +
  geom_line(data = elev_seq, aes(x = elevation, y = pred_prob),
            colour = "firebrick", linewidth = 1.1, linetype = "dashed") +
  geom_line(data = elev_seq, aes(x = elevation, y = pred_prob_poly),
            colour = "forestgreen", linewidth = 1.2) +
  labs(x = "Elevation (m)",
       y = "Habitat suitability (scaled 0–1)",
       title = "GLM with linear vs quadratic elevation effect") +
  theme_minimal(base_size = 14)
```

::: {.callout-note collapse="true" title="Why quadratic terms matter"}
Many ecological responses are **unimodal**, that is species thrive at intermediate values (e.g., mid-range temperature or elevation), while extreme conditions are typically unsuitable, except for a few highly specialized organismsa.

**Linear models cannot capture these ecological thresholds**, so across broad gradients, they may overpredict suitability in extreme environments where the species is absent.

Quadratic GLMs capture this with simple terms like **`x + x^2`**, which allow curved response shapes while remaining easy to interpret.

Although `x` and `x^2` are mathematically correlated, this is *usually not a problem* for prediction or model fitting. However, it can make *coefficient interpretation* less straightforward.

An alternative is to use **`poly(x, 2)`**, which fits **orthogonal polynomials**. These reduce numerical correlation between terms, which: - Can improve model stability, especially when predictors are on wide or skewed scales - Are useful for model selection workflows (e.g. AIC) - But have less interpretable coefficients

```{r}
#| label: glm-quad-plot
#| echo: true
#| message: false
#| warning: false

# Generate a sequence
x <- seq(0, 1, length.out = 100)

# Terms to plot
linear_term <- x
quad_simple <- x^2
quad_poly <- poly(x, 2)[, 2]  # 2nd-degree orthogonal polynomial

# Determine y-axis range to fit all curves
ymin <- min(c(linear_term, quad_simple, quad_poly))
ymax <- max(c(linear_term, quad_simple, quad_poly))

# Plot the simple quadratic term first
plot(x, quad_simple, type = "l", col = "blue", lwd = 2,
     ylab = "Value", xlab = "x", main = "Linear vs quadratic terms",
     ylim = c(ymin, ymax))

# Add linear term
lines(x, linear_term, col = "black", lwd = 2, lty = 3)

# Add orthogonal polynomial term
lines(x, quad_poly, col = "red", lwd = 2, lty = 2)

# Add a legend
legend("topleft",
       legend = c("Linear (x)", "Quadratic (x^2)", "Orthogonal poly(x, 2)"),
       col = c("black", "blue", "red"),
       lty = c(3, 1, 2),
       lwd = 2)
```

Model selection tools like AIC or cross-validation can be used to evaluate whether including a quadratic term improves predictive performance.
:::

<br>

### 1.3 GLMs with multiple predictors

While single-variable models are useful for learning, most species distributions are shaped by multiple interacting environmental drivers. Extending GLMs to include several predictors allows us to capture more realistic ecological responses.

Key considerations for multivariable GLMs:

**Ecological relevance**: Select predictors based on natural history knowledge (e.g., bats depend on both climate and topography, not just elevation).

**Multicollinearity**: strongly correlated predictors inflate variance and obscure interpretation. Tools like variance inflation factor (VIF), pairwise correlation checks, or principal component analysis (PCA) help diagnose and reduce collinearity.

**Scaling and centering**: standardising continuous predictors (e.g., scale()) improves interpretability and numerical stability.

**Interactions**: consider biologically plausible interactions (e.g., the effect of temperature may depend on rainfall).

**Interpretation**: each coefficient reflects the effect of a predictor while holding the others constant.

<br>

::: {.callout-tip collapse="true" icon="bar-chart"}
### Checking correlation among predictors and variable selection

Before fitting multivariable GLMs, it is crucial to examine correlations among predictors. Highly correlated variables can inflate standard errors, obscure interpretation, and lead to unstable models.

**Step 1: Compute correlations**

```{r}
#| label: corr-predictors
#| echo: true
#| warning: false
#| message: false

library(corrr)
library(ggplot2)
library(ggcorrplot)

# Select environmental predictors
env_vars <- sdm_df_clean %>%
  dplyr::select(starts_with("bio_"), elevation)

# Compute correlation matrix
cor_matrix <- correlate(env_vars)

# Stretch to long format
cor_long <- stretch(cor_matrix)  # columns: x, y, r

# Visualise correlation matrix directly
ggcorrplot::ggcorrplot(cor(env_vars, use = "pairwise.complete.obs"),
                       hc.order = TRUE,
                       type = "lower",
                       lab = TRUE,
                       lab_size = 3,
                       method = "circle",
                       colors = c("blue", "white", "red"),
                       title = "Pairwise correlations among predictors")
```

**Step 2: Identify highly correlated pairs**

```{r}
#| label: high-corr
#| echo: true

# Threshold for "high correlation"
high_corr_thresh <- 0.7

# Find pairs above threshold
high_corr_pairs <- cor(env_vars, use = "pairwise.complete.obs") %>%
  as.data.frame() %>%
  rownames_to_column("var1") %>%
  tidyr::pivot_longer(-var1, names_to = "var2", values_to = "r") %>%
  filter(abs(r) > high_corr_thresh & var1 != var2)

high_corr_pairs
```

**Step 3: Decide which variables to keep**

Several strategies exist:

Prior knowledge: Retain ecologically relevant variables.

Univariate model importance: Fit GLMs individually and rank by AIC or explained deviance.

Automated selection: [Dormann et al. (2013)](https://doi.org/10.1111/j.1600-0587.2012.07348.x) suggest removing the variable with lower univariate importance from each highly correlated pair.

```{r}
#| label: univariate-glm-aic
#| echo: true

# Example: compute AIC for univariate GLMs
univ_aic <- sapply(names(env_vars), function(v) {
  mod <- glm(pa ~ ., data = cbind(pa = sdm_df_clean$pa, env_vars[v]), family = binomial)
  AIC(mod)
})

tibble(variable = names(univ_aic), AIC = univ_aic) %>%
  arrange(AIC)
```

**Step 4: Reduce predictors for multivariable GLM**

After filtering for highly correlated variables and assessing univariate importance, we retain only the most relevant and weakly correlated predictors - here, bio_1 (annual mean temperature), bio_12 (annual precipitation), and elevation. This approach improves model interpretability, reduces the risk of overfitting, and ensures that the number of parameters aligns with recommended sample sizes per parameter (Guisan et al., 2017).
:::

##### Example: GLM with elevation and climate variables

```{r}
#| label: glm-multi
#| echo: true
#| message: false
#| warning: false

# Fit logistic regression with multiple predictors
glm_multi_1 <- glm(pa ~ elevation + bio_1 + bio_12,
                 data = sdm_df_clean,
                 family = binomial)

# Alternatively, fit logistic regression with multiple predictors as polynomial terms
glm_multi <- glm(pa ~ poly(elevation, 2) + poly(bio_1, 2) + poly(bio_12, 2),
                 data = sdm_df_clean,
                 family = binomial)

summary(glm_multi)
```

Here we included:

elevation (topographic constraint)

bio_1: annual mean temperature,

bio_12: annual precipitation.

This model allows us to examine how bats respond jointly to climate and topography.

##### Visualising effects

For models with several predictors, it is often more useful to visualise marginal effects rather than raw coefficients:

```{r}
# Load package for partial effects
library(effects)

# Plot marginal effect of each predictor
plot(allEffects(glm_multi))
```

Alternatively, response curves can be generated by varying one predictor while holding others at their mean or median.

**Interpretation caveats:**

With presence–pseudoabsence data, predicted values remain relative suitability, not absolute probabilities.

Including too many predictors risks overfitting. Use model selection (AIC, cross-validation) or regularisation methods to avoid this.

Always check whether fitted responses make ecological sense, not just statistical sense.

### 1.4 Model diagnostics

After fitting a GLM, it is essential to evaluate its performance and understand how well it captures species–environment relationships. Key diagnostics include **deviance, pseudo-R², and effect plots**.

**Deviance** measures how well the model fits the observed data compared to a perfect (saturated) model. Lower deviance indicates better fit. **Pseudo-R²** provides an approximate measure of explained variation, similar to the R² statistic in linear regression, but adapted for models like GLMs. Different versions exist (e.g., McFadden’s), and they help quantify how much of the variation in the response is accounted for by the predictors. **Effect plots** visualise the relationship between predictor variables and the response, showing how changes in environmental variables affect predicted species occurrence or abundance. These plots aid interpretation by revealing the shape and strength of species–environment relationships.

```{r}
#| label: glm-diagnostics
#| echo: true
#| message: false
#| warning: false

# Perform stepwise variable selection (forward/backward/both based on AIC)
glm_step <- step(glm_multi, direction = "both", trace = FALSE)

# Inspect selected model
summary(glm_step)

# 3. Compute diagnostics on selected model
cat("Residual deviance:", glm_step$deviance, "\n")
cat("Null deviance:", glm_step$null.deviance, "\n")
cat("AIC:", AIC(glm_step), "\n")

# McFadden's pseudo-R²
pseudo_r2 <- 1 - glm_step$deviance / glm_step$null.deviance
cat("McFadden's pseudo-R²:", pseudo_r2, "\n")
```

::: {.callout-note collapse="true" icon="info"}
### Interpreting relative suitability

When using presence–pseudoabsence or presence–background data, the predicted values from a logistic regression GLM do **not represent true occurrence probabilities**. Instead, they provide a **relative measure of habitat suitability** along environmental gradients.

Key points to remember:

-   Higher predicted values indicate more suitable conditions relative to other locations in the study area.
-   The absolute scale depends on the ratio of presences to pseudo-absences or background points.
-   Avoid interpreting predictions as exact probabilities of occurrence in the field.
:::

<br>

::: {.callout-tip collapse="true" icon="light-bulb"}
### Other SDM approaches: machine learning and advanced methods

While GLMs offer interpretable models, many modern SDM studies use **machine learning (ML) algorithms** to capture complex, non-linear relationships and interactions among predictors. Common approaches include:

-   **MaxEnt** – Uses presence-only data with background points; widely used for species distribution modelling.
-   **Random Forests (RF)** – Ensemble of decision trees; handles non-linearities and interactions automatically.
-   **Boosted Regression Trees (BRT / GBM)** – Sequential ensemble of weak learners to improve predictive performance.

These methods are particularly useful when ecological responses are complex or highly non-linear. They complement GLMs and will be explored further in the **“SDM Ensemble Models”** section.
:::

::: {.callout-note collapse="true" icon="info"}
### Exercises: Building and evaluating species–environment models

1.  **Compare linear vs quadratic responses:**\
    Using the same species dataset, fit two GLMs: one with a single linear predictor (e.g., bio_1) and another with a second-order polynomial (poly(bio_1, 2)). Visualise both fits and compare their AIC values and response curves. Which model better captures the ecological response?

2.  **Fit multivariable GLMs and assess collinearity:**\
    Select 4–5 bioclimatic and topographic predictors. Compute their pairwise correlation matrix, identify highly correlated pairs (e.g., \|r\| \> 0.7), and remove or justify the inclusion of collinear variables. Fit a multivariable GLM and interpret the model coefficients and pseudo-R².

3.  **Model with and without scaled predictors:**\
    Refit a GLM using 'scale()' to standardise all continuous predictors. Compare the resulting coefficients and diagnostic metrics with the unscaled model. Discuss how scaling affects interpretability, model convergence, and numerical stability, especially in models with interaction or quadratic terms.
:::

::: {.callout-note collapse="true" icon="lightbulb"}
### Literature

Araújo, M.B., Anderson, R.P., Márcia Barbosa, A., Beale, C.M., Dormann, C.F., Early, R., Garcia, R.A., Guisan, A., Maiorano, L., Naimi, B., O’Hara, R.B., Zimmermann, N.E. & Rahbek, C. (2019). **Standards for distribution models in biodiversity assessments.** *Science Advances*, 5(1), eaat4858. [doi:10.1126/sciadv.aat4858](https://doi.org/10.1126/sciadv.aat4858)

Dormann, C.F., Elith, J., Bacher, S., Buchmann, C., Carl, G., Carré, G., Marquéz, J.R.G., Gruber, B., Lafourcade, B., Leitão, P.J., Münkemüller, T., McClean, C., Osborne, P.E., Reineking, B., Schröder, B., Skidmore, A.K., Zurell, D., & Lautenbach, S. (2013). **Collinearity: a review of methods to deal with it and a simulation study evaluating their performance.** *Ecography*, 36, 27–46. <https://doi.org/10.1111/j.1600-0587.2012.07348.x>

Elith, J., & Leathwick, J. R. (2009). **Species distribution models: ecological explanation and prediction across space and time.** *Annual Review of Ecology Evolution and Systematics*, 40, 677–697. [doi:10.1146/annurev.ecolsys.110308.120159](https://doi.org/10.1146/annurev.ecolsys.110308.120159)

Franklin, J. (2010). **Moving beyond static species distribution models in support of conservation biogeography.** *Diversity and Distributions*, 16(3), 321–330. \]doi:10.1111/j.1472-4642.2010.00641.x\](https://doi.org/10.1111/j.1472-4642.2010.00641.x)

Zurell, D., Franklin, J., König, C., Bouchet, P.J., Dormann, C.F., Elith, J., Fandos, G., Feng, X., Guillera-Arroita, G., Guisan, A., Lahoz-Monfort, J.J., Leitão, P.J., Park, D.S., Peterson, A.T., Rapacciuolo, G., Schmatz, D.R., Schröder, B., Serra-Diaz, J.M., Thuiller, W. Yates, Katherine L., Zimmermann, Niklaus E., Merow, C. (2020). **A standard protocol for reporting species distribution models.** *Ecography*, 43(9), 1261–1277. [doi:10.1111/ecog.04960](https://doi.org/10.1111/ecog.04960)
:::

{"title":"Ensemble Model Fitting","markdown":{"yaml":{"title":"Ensemble Model Fitting","format":"html","editor":"visual","draft":false},"headingText":"Load required packages","containsRefs":false,"markdown":"\n\n```{r}\n#| label: setup-ensembles\n#| echo: false\n#| include: false\n#| warning: false\n#| message: false\n\nsource(\"scripts/load_packages.R\")\n\n# Load shared environmental and species data\nsource(\"scripts/shared_sdm_data.R\")\n\n# Load shared SDM models\nsource(\"scripts/shared_sdm_models.R\")\n```\n\nSpecies distribution models (SDMs) are, at best, imperfect approximations of reality. They rely on **human-defined mathematical structures** to represent complex ecological processes, forcing observational data into simplified functional forms that may not fully capture the underlying biological mechanisms. Each model is a filtered view, shaped by **assumptions, algorithmic constraints**, and the **quality of the available data**.\n\nExploring different **algorithms** for SDM has shown that every method carries its own strengths and limitations—no single model consistently outperforms others across species, regions, or scenarios. This recognition has led to the growing adoption of ensemble modelling, which combines predictions from multiple algorithms to generate more robust, reliable, and generalisable estimates of species’ potential distributions.\n\nThe core idea behind **ensemble modelling** is that each individual model captures a mix of signal (i.e. captures some of the genuine ecological patterns) and noise (errors, biases, or uncertainties). By aggregating across models, ensembles aim to amplify the signal while dampening the noise—leading to improved **predictive performance** and more defensible ecological inference.\n\nBy combining multiple models, ensemble approaches aim not only to amplify the signal and suppress the noise, but also to provide a more reliable central tendency (e.g. mean or consensus prediction) across different modelling approaches. Crucially, ensembles do more than just improve average predictive performance, as they also allow us to quantify uncertainty more effectively. By comparing variation among model predictions, we can estimate the degree of confidence in our forecasts and highlight areas of high or low agreement. This makes ensembles particularly valuable for decision-making and risk assessment under uncertainty, such as conservation planning or climate impact assessments.\n\n## 1. Ensemble Modelling Strategies\n\nEnsemble modelling in species distribution modelling (SDM) is not a single method but a framework that can incorporate different strategies for combining predictions. Broadly, ensemble methods can be grouped into three categories, depending on how models are weighted and how uncertainty is handled:\\\n\n#### 1.1 Simple averaging\n\nThe most basic ensemble method calculates the unweighted average of predictions from multiple models: • Every algorithm contributes equally to the final prediction. • Assumes all models are equally informative and reliable. • Easy to implement and interpret. When to use: When you have little prior reason to favour one model over another, or want a straightforward consensus.\\\n\n#### 1.2 Weighted averaging\n\nIn this approach, models are weighted according to performance metrics such as AUC, TSS, or cross-validated deviance: • Better-performing models contribute more heavily to the final ensemble. • Weights can be calculated based on internal validation (e.g., cross-validation AUC), independent test data, or expert judgment. When to use: When you want to prioritize models with stronger support from the data, while still retaining a diverse model set.\\\n\n#### 1.3 Consensus-based voting or thresholding\n\nHere, ensemble predictions are made by voting across binary outputs (e.g. habitat suitable/unsuitable): • A site is predicted suitable if a majority of models agree. • Can also use stricter rules (e.g. unanimity) or soft thresholds (e.g. 70% agreement). • Useful when decisions are binary (e.g. protect vs not protect) or when interpretation of continuous probabilities is unclear. When to use: In policy or management contexts that require clear thresholds for decision-making.\n\n::: {.callout-note collapse=\"true\" icon=\"info\"}\n### Practical Considerations for Ensemble Modelling\n\n#### Aligning model outputs\n\nBefore combining predictions from different SDM algorithms, it’s essential to ensure they are **aligned**:\n\n-   All models should be projected onto the **same spatial extent**, **resolution**, and use the same **environmental layers**.\n-   Predictions must be on the **same scale** (e.g. probabilities between 0 and 1).\n-   **Model names** should be clearly matched to their corresponding prediction layers or files to ensure reproducibility.\n\n#### Including uncertainty in ensembles\n\nWhile most ensemble implementations focus on generating a **central prediction** (e.g. mean or weighted mean), it is equally important to assess and communicate uncertainty:\n\n-   Include proxies for model disagreement, such as **standard deviation (SD)** across predictions.\n-   Calculate **quantiles** or **prediction intervals**, which are especially useful when communicating risk or making conservative decisions.\n-   It is good practice to report **both the ensemble mean and an uncertainty layer** (e.g. SD or interquartile range) in any spatial output intended for planning or publication.\n:::\n\n<br>\n\n## 2 Manual Ensemble Modelling\n\nAfter fitting multiple SDM algorithms and generating predictions on the same test dataset or raster stack, we can manually construct ensemble predictions by combining these outputs.\n\n#### 2.1 Prepare model predictions and evaluation metrics\n\nFor this example, suppose we have predicted probabilities from four based on GLM, GAM, BRT and randomForest models on the test data: `glm_predict_test`, `gam_predict_test`, `brt_predict_test`, `rF_predict_test` and their respective AUC values from validation: `auc_glm`, `auc_gam`, `auc_brt`, `auc_rF`\n\n#### 2.2 Simple average ensemble\n\n```{r}\n#| label: ensemble-manual-simple\n#| eval: true\n#| message: false\n#| warning: false\n\n# Combine predictions into a data frame\nmodels_predict_df <- data.frame(GLM = as.numeric(glm_predict_test),\n                      GAM = as.numeric(gam_predict_test),\n                      BRT = as.numeric(brt_predict_test),\n                      RF  = as.numeric(rF_predict_test))\n\n# Simple average ensemble prediction\nensemble_predict_simple <- rowMeans(models_predict_df)\n```\n\n#### 2.3 Weighted average ensemble\n\n```{r}\n#| label: ensemble-manual-weighted\n#| eval: true\n#| message: false\n#| warning: false\n\n# Create weight vector based on AUCs\nmodels_auc_values <- c(auc_glm, auc_gam, auc_brt, auc_rF)\nweights_auc <- models_auc_values / sum(models_auc_values)\n\n\n# Weighted average ensemble prediction\nensemble_predict_weighted <- as.numeric(as.matrix(models_predict_df) %*% weights_auc)\n```\n\n#### 2.4 Quantify ensemble uncertainty\n\n```{r}\n#| label: ensemble-manual-uncertainty\n#| eval: true\n#| message: false\n#| warning: false\n\nensemble_predict_sd <- apply(models_predict_df, 1, sd)\n```\n\n#### 2.4 Visualise ensemble prediction and uncertainty\n\n```{r}\n#| label: ensemble-manual-visual\n#| eval: true\n#| message: false\n#| warning: false\n\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Create data frame for plotting\nplot_df <- tibble(\n  Observation = 1:length(ensemble_predict_simple),\n  SimpleMean = ensemble_predict_simple,\n  WeightedMean = ensemble_predict_weighted,\n  Uncertainty = ensemble_predict_sd\n) %>%\n  pivot_longer(cols = c(SimpleMean, WeightedMean), \n               names_to = \"EnsembleType\", values_to = \"Prediction\")\n\n# Plot predictions with uncertainty ribbon\nggplot(plot_df, aes(x = Observation, y = Prediction, color = EnsembleType)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = Prediction - Uncertainty, ymax = Prediction + Uncertainty),\n              fill = \"grey80\", alpha = 0.3, color = NA) +\n  labs(title = \"Ensemble Predictions with Uncertainty\",\n       y = \"Predicted Probability\",\n       x = \"Test Sample Index\") +\n  theme_minimal()\n```\n\n## 3. Packages for Constructing Ensemble SDMs in R\n\nR offers several packages for building and combining species distribution models, each with different strengths, model algorithms, and ways of handling ensemble predictions. Three commonly used tools are **`biomod2`**, **`sdm`**, and **`ENMeval`**.\n\n### 3.1 Using `biomod2`\n\n[`biomod2`](https://cran.r-project.org/package=biomod2) is a powerful and flexible package designed specifically for ensemble species distribution modelling. It supports a wide range of modelling algorithms (e.g., GLM, GAM, RF, Maxent), provides built-in tools for data preprocessing and evaluation, and includes robust ensemble functionalities.\n\n#### Key Features:\n\n-   Supports up to ten different SDM algorithms\n-   Automates cross-validation and model tuning\n-   Allows weighted ensemble predictions\n-   Can output uncertainty layers (e.g. confidence intervals, variance)\n\n#### `biomod2` basic Workflow\n\nHere is an outline of how to run ensemble SDMs using `biomod2`:\n\n##### `biomod2` step 1: Format the input data\n\nTo use biomod2, we need to provide presence–absence data coded as 1s and 0s, corresponding geographic coordinates (longitude and latitude), a stack of environmental predictor layers, a species name, and optional also background or absence points (if not provided will be generated by the package). Here we use the data generated earlier in the worshop (and stored also as saves/shared data for this worshop) and reformat then into the required object.\n\n```{r}\n#| label: biood2-input\n#| eval: true\n#| echo: true\n#| message: false\n#| warning: false\n\nlibrary(biomod2)\nlibrary(sf)\nlibrary(terra)\nlibrary(dplyr)\n\n# Load and prepare presence data\npresence_df <- presence_sf %>%\n  mutate(resp = 1) %>%                         # Add response variable (1 = presence)\n  st_coordinates() %>%                         # Extract coordinates\n  as.data.frame() %>%                          # Convert to data frame\n  bind_cols(resp = 1)                          # Append response column again for clarity\n\n# Load and prepare background (pseudo-absence) data\nbackground_df <- background_sf %>%\n  mutate(resp = 0) %>%                         # Add response variable (0 = background)\n  st_coordinates() %>%                         # Extract coordinates\n  as.data.frame() %>%                          # Convert to data frame\n  bind_cols(resp = 0)                          # Append response column again for clarity\n\n# Combine coordinates of presence and background points\nsdm_xy <- bind_rows(\n  st_coordinates(presence_sf) %>% as.data.frame(),      # Presence coordinates\n  st_coordinates(background_sf) %>% as.data.frame()     # Background coordinates\n)\n\n# Create corresponding response vector (1 = presence, 0 = background)\nsdm_resp <- c(rep(1, nrow(presence_sf)), rep(0, nrow(background_sf)))\n\n# Rename coordinate columns to match biomod2 requirements\ncolnames(sdm_xy) <- c(\"lon\", \"lat\")\n\n# Select focal environmental layers\nenv_select <- Env_UK_stack[[c(\"bio_1\", \"bio_12\", \"elevation\")]]\n\n# Convert terra SpatRaster to RasterStack (required by biomod2)\nenv_ras <- raster::stack(env_select)\n\n# Format data for biomod2 modelling\nbiomod_data <- BIOMOD_FormatingData(\n  resp.var = sdm_resp,              # Vector of 1s and 0s\n  expl.var = env_ras,               # Environmental predictors as RasterStack\n  resp.xy = sdm_xy,                 # Coordinates of all points\n  resp.name = \"Rhinolophus_hipposideros\",  # Species name (used to label outputs)\n  PA.nb.rep = 0                     # No pseudo-absence generation needed (already supplied)\n)\n```\n\n##### `biomod2` step 2: Define and fit individual models\n\n```{r}\n#| label: biood2-fit-hidden\n#| eval: true\n#| echo: false       # hide code\n#| message: false\n#| warning: false\n#| results: 'hide'\n\n## Function to suppress everything including cat() and console output\nquiet <- function(x) {\n  sink(tempfile())              # redirect standard output\n  on.exit(sink())               # ensure we restore output\n  invisible(suppressMessages(suppressWarnings(x))) \n}\n\n# Run BIOMOD_Modeling quietly\nmyBiomodModelOut <- quiet(\n  BIOMOD_Modeling(\n    bm.format = biomod_data,\n    modeling.id = \"AllModels\",\n    models = c(\"GLM\", \"RF\", \"GBM\", \"GAM\"),\n    CV.strategy = \"random\",\n    CV.nb.rep = 2,\n    CV.perc = 0.7,\n    OPT.strategy = \"bigboss\",\n    metric.eval = c(\"TSS\", \"ROC\"),\n    var.import = 2,\n    seed.val = 42\n  )\n)\n\n```\n\n```{r}\n#| label: biood2-fit-display\n#| eval: false\n#| echo: true\n#| message: false\n#| warning: false\n\n# Set default model options (can be customised per algorithm)\nmod_options <- bm_ModelingOptions(data.type = 'binary',\n                            models = c(\"GLM\", \"RF\", \"GBM\", \"GAM\"),\n                            strategy = 'default')\n\n# Run SDMs using selected algorithms\n# Fit individual species distribution models using biomod2\nmyBiomodModelOut <- BIOMOD_Modeling(\n  bm.format = biomod_data,               # Formatted input data\n  modeling.id = \"AllModels\",             # Unique ID for this modelling run\n  models = c(\"GLM\", \"RF\", \"GBM\", \"GAM\"),  # SDM algorithms to fit\n  \n  # Cross-validation settings\n  CV.strategy = \"random\",                # Randomly split data into train/test\n  CV.nb.rep = 2,                         # Number of cross-validation replicates\n  CV.perc = 0.7,                         # 70% data used for training, 30% for testing\n  \n  # Model optimization and evaluation\n  OPT.strategy = \"bigboss\",             # Optimisation strategy (biomod2 default)\n  metric.eval = c(\"TSS\", \"ROC\"),        # Evaluation metrics to use\n  var.import = 2,                       # Number of permutations for variable importance\n  seed.val = 42                         # Random seed for reproducibility\n)\n```\n\n##### `biomod2` step 3: Build ensemble model\n\n```{r}\n#| label: biood2-ensemble\n#| eval: true\n#| echo: true\n#| message: false\n#| warning: false\n#| results: 'hide'   # hide all output, including printed messages\n\n# Inspect model evaluation metrics for each algorithm and CV replicate\nget_evaluations(myBiomodModelOut) \n\n```\n\nThese evaluation results show that some models (e.g. RF) tend to have higher ROC/TSS etc., meaning better discrimination and more confidence; others may be lower, which suggests more caution or lower predictability under your environmental data.\n\n##### `biomod2` step 4: Ensemble prediction and uncertainty mapping\n\nHere we combine models, project them spatially, generate ensemble outputs (mean probability, weighted mean, and uncertainty), then forecast ensemble to new environmental rasters\n\n```{r}\n#| label: biomod2-ensemble-and-project\n#| eval: true\n#| message: false\n#| warning: false\n\n# Project individual models to environmental raster layers\nmodel_proj <- BIOMOD_Projection(\n  bm.mod        = myBiomodModelOut,\n  new.env       = env_ras,           # raster stack of environmental predictors\n  proj.name     = \"current\",         # a label for this projection scenario\n  binary.meth   = \"TSS\",             # thresholding method for binary maps\n  compress      = FALSE\n)\n\n# Build the ensemble using all cross-validation replicates\nmyEnsembleOut <- BIOMOD_EnsembleModeling(\n  bm.mod                = myBiomodModelOut,\n  em.by                 = \"all\",                     # combine all CV runs\n  em.algo               = c(\"EMmean\", \"EMcv\", \"EMwmean\"), # different ensemble methods: mean, coefficient of variation (CV=uncertainty), weighted mean\n  metric.select         = \"TSS\",                     # metric for selecting which models to include\n  metric.select.thresh  = 0.5                        # only include individual models with TSS ≥ 0.5\n)\n\n# Apply the ensemble to the projections\nmyEnsembleProj <- BIOMOD_EnsembleForecasting(\n  bm.em   = myEnsembleOut,         # ensemble modeling object\n  bm.proj = model_proj             # projections from individual models\n)\n\n# Visualise mean suitability, CV, and weigthed suitabilty onto map\n# Extract layers from biomod2 ensemble projection\nens_stack <- get_predictions(myEnsembleProj)\n\n# Rename for clarity (adjust names if needed)\nnames(ens_stack) <- c(\"Suitability_mean\", \"CV\", \"Suitability_weighted\")\n\n# Make 0-values in the weighted layer transparent\n# Set values of 0 to NA in the weighted layer\nens_stack$Suitability_weighted[ens_stack$Suitability_weighted == 0] <- NA\n\n# Plot all three side-by-side\nplot(ens_stack,\n     main = c(\"Mean Suitability\", \"Cross-Validation Variation\", \"Weighted Suitability\"),\n     colNA = \"transparent\",       # Show NA (0-values) as transparent\n     nc = 3,                      # Number of columns in layout\n     mar = c(2, 2, 2, 4))         # Margins\n```\n\n### 3.2 Using `sdm`\n\nThe `sdm` package in R is another powerful tool for species distribution modeling that supports many algorithms, cross-validation, and ensemble modeling. It is user-friendly and integrates well with spatial data.\n\n#### Key Features:\n\n-   Supports multiple algorithms (GLM, GAM, RF, Maxent, etc.)\n-   Easy setup of cross-validation and replication\n-   Built-in ensemble modeling and projection\n-   Outputs predictions and variable importance metrics\n\n#### `sdm` basic Workflow\n\nHere is an outline of how to run ensemble SDMs using `sdm`:\n\n##### `sdm` step 1: Format the input data\n\n```{r}\n#| label: sdm-prepare-data\n#| eval: true\n#| message: false\n#| warning: false\n\nlibrary(sdm)\nlibrary(terra)\nlibrary(sf)\nlibrary(dplyr)\n\n# Convert tibbles of pre-prepared sdm training and testing data subsets to base data.frames\nsdmData_df_train <- as.data.frame(sdm_df_train)[, c(\"pa\", \"bio_1\", \"bio_12\", \"elevation\")]\nsdmData_df_test  <- as.data.frame(sdm_df_test)[, c(\"pa\", \"bio_1\", \"bio_12\", \"elevation\")]\n\n# Make sure response variable is numeric\nsdmData_df_train$pa <- as.numeric(as.character(sdmData_df_train$pa))\nsdmData_df_test$pa  <- as.numeric(as.character(sdmData_df_test$pa))\n\n# Define formula using only selected predictors\nformula_selected <- pa ~ bio_1 + bio_12 + elevation\n\n# Create sdmData object using the pre-prepared sdm training and testing data subsets\nsdmData_df <- sdm::sdmData(\n  pa ~ bio_1+bio_12+elevation,\n  train = sdmData_df_train,\n  test = sdmData_df_test\n)\n```\n\n##### `sdm` step 2: Fit models with cross-validation\n\n```{r}\n#| label: sdm-fit\n#| eval: true\n#| message: false\n#| warning: false\n\n# Fit SDMs using multiple algorithms with replication (e.g., CV)\n# Available algorithms: 'glm', 'rf', 'brt', 'svm', 'mars', 'gam', etc.\nsdm_model <- sdm::sdm(\n  formula = pa ~ bio_1 + bio_12 + elevation,\n  data = sdmData_df,\n  methods = c(\"glm\", \"gam\", \"rf\", \"brt\"),         # SDM algorithms\ntest.percent = 0   # use external test data supplied in sdmData_df\n  )\n```\n\n##### `sdm` step 3: Evaluate model performance\n\n```{r}\n#| label: sdm-eval\n#| eval: true\n#| message: false\n#| warning: false\n\n# View evaluation metrics: AUC, TSS, ...\neval_sdm <- sdm::getEvaluation(sdm_model, stat = c(\"AUC\", \"TSS\", \"sensitivity\", \"specificity\"))\n\nprint(eval_sdm)\n```\n\nAll four algorithms perform reasonably well at predicting species presence and absence, but there are differences in their strengths. The GLM (model 1) has very high sensitivity, meaning it rarely misses actual presences, but lower specificity, so it predicts some false presences. In contrast, the Random Forest (model 3) achieves the best overall balance (highest TSS) and good AUC, indicating it correctly predicts both presences and absences reliably. This illustrates why no single model is perfect, and why ensemble modelling — combining predictions from multiple algorithms — can improve robustness and account for different strengths and weaknesses of individual models.\n\n##### `sdm` step 4: Variable importance\n\n```{r}\n#| label: sdm-varimp\n#| eval: true\n#| message: false\n#| warning: false\n\n# Assess variable importance\nvarimp_sdm <- getVarImp(sdm_model, id = 1:3)  # Adjust ID to match your models if needed\nplot(varimp_sdm)\n```\n\n##### `sdm` step 5: Project model spatially\n\n```{r}\n#| label: sdm-projec \n#| message: false\n#| warning: false\n\n# Select focal environmental layers\nenv_select <- Env_UK_stack[[c(\"bio_1\", \"bio_12\", \"elevation\")]]\n\n# Project model onto environmental space\nsdm_proj <- predict(sdm_model, newdata = env_select, type=\"ensemble\")\n\n# Plot predictions\nplot(sdm_proj)\n```\n\n::: {.callout-note collapse=\"true\" icon=\"lightbulb\"}\n### Literature\n\nAraújo, M. B., & New, M. (2007). **Ensemble forecasting of species distributions.** *Trends in Ecology and Evolution*, 22(1), 42–47.\n\nDormann Carsten, F., Calabrese Justin, M., Guillera‐Arroita, G., Matechou, E., Bahn, V., Bartoń, K., . . . Hartig, F. (2018). **Model averaging in ecology: a review of Bayesian, information‐theoretic and tactical approaches for predictive inference.** *Ecological Monographs*, 88(4): 485–504. [doi:10.1002/ecm.1309](https://doi.org/10.1002/ecm.1309)\n\nHao, T., Elith, J., Lahoz-Monfort, J. J., & Guillera-Arroita, G. (2020). **Testing whether ensemble modelling is advantageous for maximising predictive performance of species distribution models.** *Ecography*, 43(4), 549–558. [doi:10.1111/ecog.04890](https://doi.org/10.1111/ecog.04890)\n\nNaimi, B., & Araújo, M. B. (2016). **sdm: a reproducible and extensible R platform for species distribution modelling.** *Ecography*, 39(4), 368–375. [doi:10.1111/ecog.01881](https://doi.org/10.1111/ecog.01881)\n\nThuiller, W., Lafourcade, B., Engler, R., & Araújo, M. B. (2009). **BIOMOD - A platform for ensemble forecasting of species distributions.** *Ecography*, 32(3), 369–373. [doi/10.1111/j.1600-0587.2008.05742.x](https://doi.org/10.1111/j.1600-0587.2008.05742.x)\n\nZurell, D., Zimmermann, N. E., Gross, H., Baltensweiler, A., Sattler, T., & Wüest, R. O. (2020). **Testing species assemblage predictions from stacked and joint species distribution models.** *Journal of Biogeography*, 47(1), 101–113. [doi:10.1111/jbi.13608](https://doi.org/10.1111/jbi.13608)\n:::\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: setup-ensembles\n#| echo: false\n#| include: false\n#| warning: false\n#| message: false\n\n# Load required packages\nsource(\"scripts/load_packages.R\")\n\n# Load shared environmental and species data\nsource(\"scripts/shared_sdm_data.R\")\n\n# Load shared SDM models\nsource(\"scripts/shared_sdm_models.R\")\n```\n\nSpecies distribution models (SDMs) are, at best, imperfect approximations of reality. They rely on **human-defined mathematical structures** to represent complex ecological processes, forcing observational data into simplified functional forms that may not fully capture the underlying biological mechanisms. Each model is a filtered view, shaped by **assumptions, algorithmic constraints**, and the **quality of the available data**.\n\nExploring different **algorithms** for SDM has shown that every method carries its own strengths and limitations—no single model consistently outperforms others across species, regions, or scenarios. This recognition has led to the growing adoption of ensemble modelling, which combines predictions from multiple algorithms to generate more robust, reliable, and generalisable estimates of species’ potential distributions.\n\nThe core idea behind **ensemble modelling** is that each individual model captures a mix of signal (i.e. captures some of the genuine ecological patterns) and noise (errors, biases, or uncertainties). By aggregating across models, ensembles aim to amplify the signal while dampening the noise—leading to improved **predictive performance** and more defensible ecological inference.\n\nBy combining multiple models, ensemble approaches aim not only to amplify the signal and suppress the noise, but also to provide a more reliable central tendency (e.g. mean or consensus prediction) across different modelling approaches. Crucially, ensembles do more than just improve average predictive performance, as they also allow us to quantify uncertainty more effectively. By comparing variation among model predictions, we can estimate the degree of confidence in our forecasts and highlight areas of high or low agreement. This makes ensembles particularly valuable for decision-making and risk assessment under uncertainty, such as conservation planning or climate impact assessments.\n\n## 1. Ensemble Modelling Strategies\n\nEnsemble modelling in species distribution modelling (SDM) is not a single method but a framework that can incorporate different strategies for combining predictions. Broadly, ensemble methods can be grouped into three categories, depending on how models are weighted and how uncertainty is handled:\\\n\n#### 1.1 Simple averaging\n\nThe most basic ensemble method calculates the unweighted average of predictions from multiple models: • Every algorithm contributes equally to the final prediction. • Assumes all models are equally informative and reliable. • Easy to implement and interpret. When to use: When you have little prior reason to favour one model over another, or want a straightforward consensus.\\\n\n#### 1.2 Weighted averaging\n\nIn this approach, models are weighted according to performance metrics such as AUC, TSS, or cross-validated deviance: • Better-performing models contribute more heavily to the final ensemble. • Weights can be calculated based on internal validation (e.g., cross-validation AUC), independent test data, or expert judgment. When to use: When you want to prioritize models with stronger support from the data, while still retaining a diverse model set.\\\n\n#### 1.3 Consensus-based voting or thresholding\n\nHere, ensemble predictions are made by voting across binary outputs (e.g. habitat suitable/unsuitable): • A site is predicted suitable if a majority of models agree. • Can also use stricter rules (e.g. unanimity) or soft thresholds (e.g. 70% agreement). • Useful when decisions are binary (e.g. protect vs not protect) or when interpretation of continuous probabilities is unclear. When to use: In policy or management contexts that require clear thresholds for decision-making.\n\n::: {.callout-note collapse=\"true\" icon=\"info\"}\n### Practical Considerations for Ensemble Modelling\n\n#### Aligning model outputs\n\nBefore combining predictions from different SDM algorithms, it’s essential to ensure they are **aligned**:\n\n-   All models should be projected onto the **same spatial extent**, **resolution**, and use the same **environmental layers**.\n-   Predictions must be on the **same scale** (e.g. probabilities between 0 and 1).\n-   **Model names** should be clearly matched to their corresponding prediction layers or files to ensure reproducibility.\n\n#### Including uncertainty in ensembles\n\nWhile most ensemble implementations focus on generating a **central prediction** (e.g. mean or weighted mean), it is equally important to assess and communicate uncertainty:\n\n-   Include proxies for model disagreement, such as **standard deviation (SD)** across predictions.\n-   Calculate **quantiles** or **prediction intervals**, which are especially useful when communicating risk or making conservative decisions.\n-   It is good practice to report **both the ensemble mean and an uncertainty layer** (e.g. SD or interquartile range) in any spatial output intended for planning or publication.\n:::\n\n<br>\n\n## 2 Manual Ensemble Modelling\n\nAfter fitting multiple SDM algorithms and generating predictions on the same test dataset or raster stack, we can manually construct ensemble predictions by combining these outputs.\n\n#### 2.1 Prepare model predictions and evaluation metrics\n\nFor this example, suppose we have predicted probabilities from four based on GLM, GAM, BRT and randomForest models on the test data: `glm_predict_test`, `gam_predict_test`, `brt_predict_test`, `rF_predict_test` and their respective AUC values from validation: `auc_glm`, `auc_gam`, `auc_brt`, `auc_rF`\n\n#### 2.2 Simple average ensemble\n\n```{r}\n#| label: ensemble-manual-simple\n#| eval: true\n#| message: false\n#| warning: false\n\n# Combine predictions into a data frame\nmodels_predict_df <- data.frame(GLM = as.numeric(glm_predict_test),\n                      GAM = as.numeric(gam_predict_test),\n                      BRT = as.numeric(brt_predict_test),\n                      RF  = as.numeric(rF_predict_test))\n\n# Simple average ensemble prediction\nensemble_predict_simple <- rowMeans(models_predict_df)\n```\n\n#### 2.3 Weighted average ensemble\n\n```{r}\n#| label: ensemble-manual-weighted\n#| eval: true\n#| message: false\n#| warning: false\n\n# Create weight vector based on AUCs\nmodels_auc_values <- c(auc_glm, auc_gam, auc_brt, auc_rF)\nweights_auc <- models_auc_values / sum(models_auc_values)\n\n\n# Weighted average ensemble prediction\nensemble_predict_weighted <- as.numeric(as.matrix(models_predict_df) %*% weights_auc)\n```\n\n#### 2.4 Quantify ensemble uncertainty\n\n```{r}\n#| label: ensemble-manual-uncertainty\n#| eval: true\n#| message: false\n#| warning: false\n\nensemble_predict_sd <- apply(models_predict_df, 1, sd)\n```\n\n#### 2.4 Visualise ensemble prediction and uncertainty\n\n```{r}\n#| label: ensemble-manual-visual\n#| eval: true\n#| message: false\n#| warning: false\n\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Create data frame for plotting\nplot_df <- tibble(\n  Observation = 1:length(ensemble_predict_simple),\n  SimpleMean = ensemble_predict_simple,\n  WeightedMean = ensemble_predict_weighted,\n  Uncertainty = ensemble_predict_sd\n) %>%\n  pivot_longer(cols = c(SimpleMean, WeightedMean), \n               names_to = \"EnsembleType\", values_to = \"Prediction\")\n\n# Plot predictions with uncertainty ribbon\nggplot(plot_df, aes(x = Observation, y = Prediction, color = EnsembleType)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = Prediction - Uncertainty, ymax = Prediction + Uncertainty),\n              fill = \"grey80\", alpha = 0.3, color = NA) +\n  labs(title = \"Ensemble Predictions with Uncertainty\",\n       y = \"Predicted Probability\",\n       x = \"Test Sample Index\") +\n  theme_minimal()\n```\n\n## 3. Packages for Constructing Ensemble SDMs in R\n\nR offers several packages for building and combining species distribution models, each with different strengths, model algorithms, and ways of handling ensemble predictions. Three commonly used tools are **`biomod2`**, **`sdm`**, and **`ENMeval`**.\n\n### 3.1 Using `biomod2`\n\n[`biomod2`](https://cran.r-project.org/package=biomod2) is a powerful and flexible package designed specifically for ensemble species distribution modelling. It supports a wide range of modelling algorithms (e.g., GLM, GAM, RF, Maxent), provides built-in tools for data preprocessing and evaluation, and includes robust ensemble functionalities.\n\n#### Key Features:\n\n-   Supports up to ten different SDM algorithms\n-   Automates cross-validation and model tuning\n-   Allows weighted ensemble predictions\n-   Can output uncertainty layers (e.g. confidence intervals, variance)\n\n#### `biomod2` basic Workflow\n\nHere is an outline of how to run ensemble SDMs using `biomod2`:\n\n##### `biomod2` step 1: Format the input data\n\nTo use biomod2, we need to provide presence–absence data coded as 1s and 0s, corresponding geographic coordinates (longitude and latitude), a stack of environmental predictor layers, a species name, and optional also background or absence points (if not provided will be generated by the package). Here we use the data generated earlier in the worshop (and stored also as saves/shared data for this worshop) and reformat then into the required object.\n\n```{r}\n#| label: biood2-input\n#| eval: true\n#| echo: true\n#| message: false\n#| warning: false\n\nlibrary(biomod2)\nlibrary(sf)\nlibrary(terra)\nlibrary(dplyr)\n\n# Load and prepare presence data\npresence_df <- presence_sf %>%\n  mutate(resp = 1) %>%                         # Add response variable (1 = presence)\n  st_coordinates() %>%                         # Extract coordinates\n  as.data.frame() %>%                          # Convert to data frame\n  bind_cols(resp = 1)                          # Append response column again for clarity\n\n# Load and prepare background (pseudo-absence) data\nbackground_df <- background_sf %>%\n  mutate(resp = 0) %>%                         # Add response variable (0 = background)\n  st_coordinates() %>%                         # Extract coordinates\n  as.data.frame() %>%                          # Convert to data frame\n  bind_cols(resp = 0)                          # Append response column again for clarity\n\n# Combine coordinates of presence and background points\nsdm_xy <- bind_rows(\n  st_coordinates(presence_sf) %>% as.data.frame(),      # Presence coordinates\n  st_coordinates(background_sf) %>% as.data.frame()     # Background coordinates\n)\n\n# Create corresponding response vector (1 = presence, 0 = background)\nsdm_resp <- c(rep(1, nrow(presence_sf)), rep(0, nrow(background_sf)))\n\n# Rename coordinate columns to match biomod2 requirements\ncolnames(sdm_xy) <- c(\"lon\", \"lat\")\n\n# Select focal environmental layers\nenv_select <- Env_UK_stack[[c(\"bio_1\", \"bio_12\", \"elevation\")]]\n\n# Convert terra SpatRaster to RasterStack (required by biomod2)\nenv_ras <- raster::stack(env_select)\n\n# Format data for biomod2 modelling\nbiomod_data <- BIOMOD_FormatingData(\n  resp.var = sdm_resp,              # Vector of 1s and 0s\n  expl.var = env_ras,               # Environmental predictors as RasterStack\n  resp.xy = sdm_xy,                 # Coordinates of all points\n  resp.name = \"Rhinolophus_hipposideros\",  # Species name (used to label outputs)\n  PA.nb.rep = 0                     # No pseudo-absence generation needed (already supplied)\n)\n```\n\n##### `biomod2` step 2: Define and fit individual models\n\n```{r}\n#| label: biood2-fit-hidden\n#| eval: true\n#| echo: false       # hide code\n#| message: false\n#| warning: false\n#| results: 'hide'\n\n## Function to suppress everything including cat() and console output\nquiet <- function(x) {\n  sink(tempfile())              # redirect standard output\n  on.exit(sink())               # ensure we restore output\n  invisible(suppressMessages(suppressWarnings(x))) \n}\n\n# Run BIOMOD_Modeling quietly\nmyBiomodModelOut <- quiet(\n  BIOMOD_Modeling(\n    bm.format = biomod_data,\n    modeling.id = \"AllModels\",\n    models = c(\"GLM\", \"RF\", \"GBM\", \"GAM\"),\n    CV.strategy = \"random\",\n    CV.nb.rep = 2,\n    CV.perc = 0.7,\n    OPT.strategy = \"bigboss\",\n    metric.eval = c(\"TSS\", \"ROC\"),\n    var.import = 2,\n    seed.val = 42\n  )\n)\n\n```\n\n```{r}\n#| label: biood2-fit-display\n#| eval: false\n#| echo: true\n#| message: false\n#| warning: false\n\n# Set default model options (can be customised per algorithm)\nmod_options <- bm_ModelingOptions(data.type = 'binary',\n                            models = c(\"GLM\", \"RF\", \"GBM\", \"GAM\"),\n                            strategy = 'default')\n\n# Run SDMs using selected algorithms\n# Fit individual species distribution models using biomod2\nmyBiomodModelOut <- BIOMOD_Modeling(\n  bm.format = biomod_data,               # Formatted input data\n  modeling.id = \"AllModels\",             # Unique ID for this modelling run\n  models = c(\"GLM\", \"RF\", \"GBM\", \"GAM\"),  # SDM algorithms to fit\n  \n  # Cross-validation settings\n  CV.strategy = \"random\",                # Randomly split data into train/test\n  CV.nb.rep = 2,                         # Number of cross-validation replicates\n  CV.perc = 0.7,                         # 70% data used for training, 30% for testing\n  \n  # Model optimization and evaluation\n  OPT.strategy = \"bigboss\",             # Optimisation strategy (biomod2 default)\n  metric.eval = c(\"TSS\", \"ROC\"),        # Evaluation metrics to use\n  var.import = 2,                       # Number of permutations for variable importance\n  seed.val = 42                         # Random seed for reproducibility\n)\n```\n\n##### `biomod2` step 3: Build ensemble model\n\n```{r}\n#| label: biood2-ensemble\n#| eval: true\n#| echo: true\n#| message: false\n#| warning: false\n#| results: 'hide'   # hide all output, including printed messages\n\n# Inspect model evaluation metrics for each algorithm and CV replicate\nget_evaluations(myBiomodModelOut) \n\n```\n\nThese evaluation results show that some models (e.g. RF) tend to have higher ROC/TSS etc., meaning better discrimination and more confidence; others may be lower, which suggests more caution or lower predictability under your environmental data.\n\n##### `biomod2` step 4: Ensemble prediction and uncertainty mapping\n\nHere we combine models, project them spatially, generate ensemble outputs (mean probability, weighted mean, and uncertainty), then forecast ensemble to new environmental rasters\n\n```{r}\n#| label: biomod2-ensemble-and-project\n#| eval: true\n#| message: false\n#| warning: false\n\n# Project individual models to environmental raster layers\nmodel_proj <- BIOMOD_Projection(\n  bm.mod        = myBiomodModelOut,\n  new.env       = env_ras,           # raster stack of environmental predictors\n  proj.name     = \"current\",         # a label for this projection scenario\n  binary.meth   = \"TSS\",             # thresholding method for binary maps\n  compress      = FALSE\n)\n\n# Build the ensemble using all cross-validation replicates\nmyEnsembleOut <- BIOMOD_EnsembleModeling(\n  bm.mod                = myBiomodModelOut,\n  em.by                 = \"all\",                     # combine all CV runs\n  em.algo               = c(\"EMmean\", \"EMcv\", \"EMwmean\"), # different ensemble methods: mean, coefficient of variation (CV=uncertainty), weighted mean\n  metric.select         = \"TSS\",                     # metric for selecting which models to include\n  metric.select.thresh  = 0.5                        # only include individual models with TSS ≥ 0.5\n)\n\n# Apply the ensemble to the projections\nmyEnsembleProj <- BIOMOD_EnsembleForecasting(\n  bm.em   = myEnsembleOut,         # ensemble modeling object\n  bm.proj = model_proj             # projections from individual models\n)\n\n# Visualise mean suitability, CV, and weigthed suitabilty onto map\n# Extract layers from biomod2 ensemble projection\nens_stack <- get_predictions(myEnsembleProj)\n\n# Rename for clarity (adjust names if needed)\nnames(ens_stack) <- c(\"Suitability_mean\", \"CV\", \"Suitability_weighted\")\n\n# Make 0-values in the weighted layer transparent\n# Set values of 0 to NA in the weighted layer\nens_stack$Suitability_weighted[ens_stack$Suitability_weighted == 0] <- NA\n\n# Plot all three side-by-side\nplot(ens_stack,\n     main = c(\"Mean Suitability\", \"Cross-Validation Variation\", \"Weighted Suitability\"),\n     colNA = \"transparent\",       # Show NA (0-values) as transparent\n     nc = 3,                      # Number of columns in layout\n     mar = c(2, 2, 2, 4))         # Margins\n```\n\n### 3.2 Using `sdm`\n\nThe `sdm` package in R is another powerful tool for species distribution modeling that supports many algorithms, cross-validation, and ensemble modeling. It is user-friendly and integrates well with spatial data.\n\n#### Key Features:\n\n-   Supports multiple algorithms (GLM, GAM, RF, Maxent, etc.)\n-   Easy setup of cross-validation and replication\n-   Built-in ensemble modeling and projection\n-   Outputs predictions and variable importance metrics\n\n#### `sdm` basic Workflow\n\nHere is an outline of how to run ensemble SDMs using `sdm`:\n\n##### `sdm` step 1: Format the input data\n\n```{r}\n#| label: sdm-prepare-data\n#| eval: true\n#| message: false\n#| warning: false\n\nlibrary(sdm)\nlibrary(terra)\nlibrary(sf)\nlibrary(dplyr)\n\n# Convert tibbles of pre-prepared sdm training and testing data subsets to base data.frames\nsdmData_df_train <- as.data.frame(sdm_df_train)[, c(\"pa\", \"bio_1\", \"bio_12\", \"elevation\")]\nsdmData_df_test  <- as.data.frame(sdm_df_test)[, c(\"pa\", \"bio_1\", \"bio_12\", \"elevation\")]\n\n# Make sure response variable is numeric\nsdmData_df_train$pa <- as.numeric(as.character(sdmData_df_train$pa))\nsdmData_df_test$pa  <- as.numeric(as.character(sdmData_df_test$pa))\n\n# Define formula using only selected predictors\nformula_selected <- pa ~ bio_1 + bio_12 + elevation\n\n# Create sdmData object using the pre-prepared sdm training and testing data subsets\nsdmData_df <- sdm::sdmData(\n  pa ~ bio_1+bio_12+elevation,\n  train = sdmData_df_train,\n  test = sdmData_df_test\n)\n```\n\n##### `sdm` step 2: Fit models with cross-validation\n\n```{r}\n#| label: sdm-fit\n#| eval: true\n#| message: false\n#| warning: false\n\n# Fit SDMs using multiple algorithms with replication (e.g., CV)\n# Available algorithms: 'glm', 'rf', 'brt', 'svm', 'mars', 'gam', etc.\nsdm_model <- sdm::sdm(\n  formula = pa ~ bio_1 + bio_12 + elevation,\n  data = sdmData_df,\n  methods = c(\"glm\", \"gam\", \"rf\", \"brt\"),         # SDM algorithms\ntest.percent = 0   # use external test data supplied in sdmData_df\n  )\n```\n\n##### `sdm` step 3: Evaluate model performance\n\n```{r}\n#| label: sdm-eval\n#| eval: true\n#| message: false\n#| warning: false\n\n# View evaluation metrics: AUC, TSS, ...\neval_sdm <- sdm::getEvaluation(sdm_model, stat = c(\"AUC\", \"TSS\", \"sensitivity\", \"specificity\"))\n\nprint(eval_sdm)\n```\n\nAll four algorithms perform reasonably well at predicting species presence and absence, but there are differences in their strengths. The GLM (model 1) has very high sensitivity, meaning it rarely misses actual presences, but lower specificity, so it predicts some false presences. In contrast, the Random Forest (model 3) achieves the best overall balance (highest TSS) and good AUC, indicating it correctly predicts both presences and absences reliably. This illustrates why no single model is perfect, and why ensemble modelling — combining predictions from multiple algorithms — can improve robustness and account for different strengths and weaknesses of individual models.\n\n##### `sdm` step 4: Variable importance\n\n```{r}\n#| label: sdm-varimp\n#| eval: true\n#| message: false\n#| warning: false\n\n# Assess variable importance\nvarimp_sdm <- getVarImp(sdm_model, id = 1:3)  # Adjust ID to match your models if needed\nplot(varimp_sdm)\n```\n\n##### `sdm` step 5: Project model spatially\n\n```{r}\n#| label: sdm-projec \n#| message: false\n#| warning: false\n\n# Select focal environmental layers\nenv_select <- Env_UK_stack[[c(\"bio_1\", \"bio_12\", \"elevation\")]]\n\n# Project model onto environmental space\nsdm_proj <- predict(sdm_model, newdata = env_select, type=\"ensemble\")\n\n# Plot predictions\nplot(sdm_proj)\n```\n\n::: {.callout-note collapse=\"true\" icon=\"lightbulb\"}\n### Literature\n\nAraújo, M. B., & New, M. (2007). **Ensemble forecasting of species distributions.** *Trends in Ecology and Evolution*, 22(1), 42–47.\n\nDormann Carsten, F., Calabrese Justin, M., Guillera‐Arroita, G., Matechou, E., Bahn, V., Bartoń, K., . . . Hartig, F. (2018). **Model averaging in ecology: a review of Bayesian, information‐theoretic and tactical approaches for predictive inference.** *Ecological Monographs*, 88(4): 485–504. [doi:10.1002/ecm.1309](https://doi.org/10.1002/ecm.1309)\n\nHao, T., Elith, J., Lahoz-Monfort, J. J., & Guillera-Arroita, G. (2020). **Testing whether ensemble modelling is advantageous for maximising predictive performance of species distribution models.** *Ecography*, 43(4), 549–558. [doi:10.1111/ecog.04890](https://doi.org/10.1111/ecog.04890)\n\nNaimi, B., & Araújo, M. B. (2016). **sdm: a reproducible and extensible R platform for species distribution modelling.** *Ecography*, 39(4), 368–375. [doi:10.1111/ecog.01881](https://doi.org/10.1111/ecog.01881)\n\nThuiller, W., Lafourcade, B., Engler, R., & Araújo, M. B. (2009). **BIOMOD - A platform for ensemble forecasting of species distributions.** *Ecography*, 32(3), 369–373. [doi/10.1111/j.1600-0587.2008.05742.x](https://doi.org/10.1111/j.1600-0587.2008.05742.x)\n\nZurell, D., Zimmermann, N. E., Gross, H., Baltensweiler, A., Sattler, T., & Wüest, R. O. (2020). **Testing species assemblage predictions from stacked and joint species distribution models.** *Journal of Biogeography*, 47(1), 101–113. [doi:10.1111/jbi.13608](https://doi.org/10.1111/jbi.13608)\n:::\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":true,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"setup":"scripts/load_packages.R","message":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"css":["styles.css"],"output-file":"page_SDM.9_SDMEnsembleModelFitting.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.24","pages":["index.qmd","page_SDM.1_DataPreparation.qmd"],"theme":"cosmo","toc-location":"left","page-layout":"full","code-copy":true,"allow-html":true,"title":"Ensemble Model Fitting","editor":"visual","draft":false},"extensions":{"book":{"multiFile":true}}}},"draft":false,"projectFormats":["html","pdf"]}